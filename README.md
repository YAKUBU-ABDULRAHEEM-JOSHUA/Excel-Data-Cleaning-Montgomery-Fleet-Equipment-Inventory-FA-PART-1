# Excel-Data-Cleaning-Montgomery-Fleet-Equipment-Inventory-FA-PART-1
Data Cleaning of Montgomery Fleet Equipment Inventory using microsoft excel spreasdsheet (handling duplicates,blank rows and inconsistent department names)
## Objective
The objective of this project was to **clean and prepare the Montgomery-Fleet-Equipment-Inventory.cvs dataset** for analysis by removing duplicates, errors, inconsistencies issues. This ensures that the data is reliable, accurate and ready for further reporting and insights.

## Tools Used
Microsoft Excel : Filters, Condition Formatting, Find & replace , Flash Fill

## Data Cleaning Steps
1. Adjusted Column Widths : Expanded all column widths to ensure the data in each cell was visible and easy to interpret.
2. Removed Empty Rows : Applied filter to identify blank rows and deleted them to maintain dataset completeness.
3. Removed Duplicates: Used conditional formatting to preview duplicate rercord before removing them. This approach maintained data integrity by allowing review before delection
4. Fixed inconsistent Spacing : Applied  find and replace feature to remove double spaces across dataset, ensuring consistency in formatting
5. Correct Wrong Spellings :Used the spelling check in the review tab to correct all incorrect spellings
6. Corrected Department Name : During import, department names were incorrectly split across two columns. I used flash fill to merge and reconstruct accurate department names into a single column. Then I deleted redundant column after correction.

## Results
1. Clean dataset free from blank rows,duplicates and inconsistent formatting
2. Department Names standardized into a single, correct column
3. Final dataset is now accurate, consistent and ready for analysis

## Project Files
- Montgomery_Fleet_Equipment_Inventory_FA_PART_1_START.CSV   ---> Original Dataset (Uncleaned)
- Montgomery_Fleet_Equipment_Inventory_FA_PART_1_END.XLSX    ---> Cleaned Dataset

## Key Takeaway
This project demonstrates my ability to use **Excel's core data cleaning tools** to transform messy raw data into a clean, reliable dataset suitable for further analysis and reporting.
